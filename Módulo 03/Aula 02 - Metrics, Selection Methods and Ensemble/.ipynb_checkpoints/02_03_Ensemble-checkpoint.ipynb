{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comitês de máquinas (Ensemble)\n",
    "\n",
    "Os comitês de máquinas são a combinação de um mais classificadores / regressores para chegar a um rótulo. Nesse sentido, podem ser empregados classificadores que foram treinados com diferentes conjuntos de dados, ou poderão ser empregados classificadores que foram treinados no mesmo conjunto de dados utilizando estratégias de aprendizado diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging com 1 método (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonardofaverobocardi/anaconda3/anaconda3/envs/python3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/leonardofaverobocardi/anaconda3/anaconda3/envs/python3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de KNeighbors simples: 0.9627899114966898\n",
      "Acurácia de KNeighbors Bagging (c/ 10 estimators): 0.9560881378502464\n",
      "Acurácia de KNeighbors Bagging (c/ 100 estimators): 0.9572027558600477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print('Acurácia de KNeighbors simples:', scores.mean())\n",
    "\n",
    "model = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5, random_state = 42)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print('Acurácia de KNeighbors Bagging (c/ 10 estimators):', scores.mean())\n",
    "\n",
    "model = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5, n_estimators=100, random_state = 42)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print('Acurácia de KNeighbors Bagging (c/ 100 estimators):', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging com 3 métodos diferentes (Decision Tree, Random Forest, Extra Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de Decision Tree puro: 0.7848324611117669\n",
      "Acurácia de Random Forest: 0.9327128323578864\n",
      "Acurácia de Extreme Randomized Trees: 0.9521900955939782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Acurácia de Decision Tree puro:', scores.mean())\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Acurácia de Random Forest:', scores.mean())\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=50, max_depth=None, min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print('Acurácia de Extreme Randomized Trees:', scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.91 (+/- 0.03) [Logistic Regression]\n",
      "Acurácia: 0.90 (+/- 0.02) [Random Forest]\n",
      "Acurácia: 0.81 (+/- 0.03) [naive Bayes]\n",
      "Acurácia: 0.92 (+/- 0.03) [Ensemble]\n",
      "--------------------\n",
      "Acurácia: 0.91 (+/- 0.03) [Logistic Regression]\n",
      "Acurácia: 0.90 (+/- 0.02) [Random Forest]\n",
      "Acurácia: 0.91 (+/- 0.03) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb',clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"Acurácia: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n",
    "print('-'*20)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, eclf], ['Logistic Regression', 'Random Forest', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"Acurácia: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de Gradient Boosting Tree: 0.9355044340092137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.3, max_depth=2, random_state=0)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print('Acurácia de Gradient Boosting Tree:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício\n",
    "\n",
    "(1) Em um novo notebook, avaliar a combinação das técnicas de seleção de atributos e redução de dimensionalidade com as métricas de desempenho apropriadas e verificar se os comitês de máquina (ensemble) auxiliam na melhora do resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Dica: Tire as medidas de tempo para conhecer a relação de custo e desempenho dos modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
